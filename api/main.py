# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KiAPkRW1mSXaLkJPcrypDT2X9eosICBk
"""

from fastapi import FastAPI
from pydantic import BaseModel
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, roc_curve, roc_auc_score, auc, confusion_matrix
from sklearn.model_selection import train_test_split
import pandas as pd
import joblib
import requests
import os

SEED = 42
app = FastAPI()

class ModelInput(BaseModel):
  model_type: str  # baseline / stacked
  model_name: str # AdaBoost / CatBoost / ...
  sampling : str # SMOTE / ADASYN / TomekLinks / None

def get_model_path(model_type, model_name, sampling):
  if sampling == "none":
    filename = f"{model_type}_{model_name}_without_smote.pkl"
  else:
    filename = f"{model_type}_{model_name}_with_{sampling}.pkl"

  local_path = os.path.join("models", filename)
  github_url = f"https://raw.githubusercontent.com/HMate02/Pulsar_Detection/main/api/models/{model_name}/{filename}"

  if not os.path.exists("models"):
    os.makedirs("models")

  if not os.path.exists(local_path):
    r = requests.get(github_url)
    if r.status_code == 200:
      with open(local_path, "wb") as f:
        f.write(r.content)
    else:
      raise FileNotFoundError(f"A modell nem található: {github_url}")

  return local_path

@app.post("/predict_model")
def predict_model(input: ModelInput):
  model_path = get_model_path(input.model_type, input.model_name, input.sampling)
  model = joblib.load(model_path)

  htru2_data = pd.read_csv('https://raw.githubusercontent.com/szbela87/ml_22_elteik/main/data/HTRU_2.csv', header=None)
  X = htru2_data.drop("class", axis=1)
  y = htru2_data["class"]

  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=SEED)
  X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1/0.9, random_state=SEED)

  model.fit(X_train, y_train)

  y_pred = model.predict(X_test)

  accuracy = accuracy_score(y_test, y_pred)
  auc = roc_auc_score(y_test, y_pred)
  f1 = f1_score(y_test, y_pred)
  precision = precision_score(y_test, y_pred)
  recall = recall_score(y_test, y_pred)
  conf_matrix = confusion_matrix(y_test, y_pred)

  return {
      "accuracy" : accuracy,
      "auc" : auc,
      "f1" : f1,
      "precision" : precision,
      "recall" : recall,
      "confusion_matrix" : conf_matrix.tolist()
  }

